{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An End-to-End Text Classification System\n",
    "\n",
    "In this workshop you will implement a text classification system from scratch. This means that we will not rely on Keras' convenient data sets. These data sets are pre-processed and it will be useful if you know how to tokenise and find the word indices of text collections not provided by Keras.\n",
    "\n",
    "The task will be to classify questions. NLTK has a corpus of questions and their question types according to a particular classification scheme (e.g. DESC refers to a question expecting a descriptive answer, such as one starting with \"How\"; HUM refers to a question expecting an answer referring to a human). Here's some example of use of the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/qc.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"qc\")\n",
    "from nltk.corpus import qc\n",
    "train = qc.tuples(\"train.txt\")\n",
    "test = qc.tuples(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DESC:manner', 'How did serfdom develop in and then leave Russia ?'),\n",
       " ('ENTY:cremat', 'What films featured the character Popeye Doyle ?'),\n",
       " ('DESC:manner', \"How can I find a list of celebrities ' real names ?\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM:dist', 'How far is it from Denver to Aspen ?'),\n",
       " ('LOC:city', 'What county is Modesto , California in ?'),\n",
       " ('HUM:desc', 'Who was Galileo ?')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Find all question types\n",
    "Write Python code that lists all the possible question types of the training set (**remember: never look at the test set**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Find all general types\n",
    "\n",
    "The question types have two parts. The first part describes a general type, and the second part defines a subtype. For example, the question type `DESC:manner` belongs to the general `DESC` type and within that type to the `manner` subtype. Let's focus on the general types only. Write Python code that lists all the possible general types (there are 6 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Partition the data\n",
    "There is a train and test data, but for this exercise we want to have a partition into train, dev-test, and test. In this exercise, combine all data into one array and do a 3-way partition into train, dev-test, and test. Make sure that you shuffle the data prior to doing the partition. Also, make sure that you only use the general label types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train = ...\n",
    "q_devtest = ...\n",
    "q_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Tokenise the data\n",
    "\n",
    "Use Keras' tokeniser to tokenise all the data. For this exercise we will use only the 100 most frequent words in the training set (since you aren't supposed to use the dev-test or test sets to extract features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 100\n",
    "indices_train = ...\n",
    "indices_devtest = ...\n",
    "indices_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Vectorize the data\n",
    "The following code shows the distribution of lengths of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  43., 1001., 1327.,  815.,  169.,  162.,   43.,    7.,    2.,\n",
       "           2.]),\n",
       " array([ 0. ,  1.8,  3.6,  5.4,  7.2,  9. , 10.8, 12.6, 14.4, 16.2, 18. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist([len(d) for d in indices_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that the longest question in the training data has 18 word indices, but by far most of the questions have at least 10. Based on this, use Keras' `pad_sequences` to vectorize the questions into sequences of 10 word indices. The default will be to truncate the beginning, but we want to truncate the end (since the first words of a question are often very important to determine the question type). For this you can use the option `truncating='post'`: https://keras.io/preprocessing/sequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "x_train = ...\n",
    "x_devtest = ...\n",
    "x_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Vectorise the labels\n",
    "Convert the labels to one-hot encoding. If you use Keras' `to_categorical` you would first need to convert the labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ...\n",
    "y_devtest = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Define the model\n",
    "\n",
    "Define a model for classification. For this model, use a feedforward architecture with an embedding layer of size 20, a layer that computes the average of word embeddings (use `GlobalAveragePooling1D`), a hidden layer of 16 units, and `relu` activation. You need to determine the size and activation of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Train and evaluate\n",
    "Train your model. In the process you need to determine the optimal number of epochs. Then answer the following questions:\n",
    "1. What was the optimal number of epochs and how did you determine this?\n",
    "2. Is the system overfitting? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise: Data exploration\n",
    "Plot the distribution of labels in the training data and compare with the distribution of labels in the devtest data. Plot also the distribution of predictions in the devtest data. What can you learn from this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise: Improve your system\n",
    "\n",
    "Try the following options:\n",
    "1. Use pre-trained word embeddings\n",
    "2. Use recurrent neural networks.\n",
    "\n",
    "Feel free to try each option separately and in combination, and compare the results. Feel also free to try with other variants of the initial architecture, such as:\n",
    "1. Introducing more hidden layers.\n",
    "2. Changing the size of embeddings.\n",
    "3. Changing the number of units in the hidden layer(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
